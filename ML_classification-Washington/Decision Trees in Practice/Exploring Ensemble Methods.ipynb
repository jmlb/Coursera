{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Ensemble Methods\n",
    "In this assignment, we will explore the use of boosting.\n",
    "In this homework we will explore the use of boosting. For this assignment, we will use the pre-implemented gradient boosted trees in Graphlab-Create. You will:\n",
    "\n",
    "Use SFrames to do some feature engineering.\n",
    "Train a boosted ensemble of decision-trees (gradient boosted trees) on the lending club dataset.\n",
    "Predict whether a loan will default along with prediction probabilities (on a validation set).\n",
    "Evaluate the trained model and compare it with a baseline.\n",
    "Find the most positive and negative loans using the learned model.\n",
    "Explore how the number of trees influences classification performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in original data file: 68\n",
      "Number of features in selected columns: 24\n",
      "Number of features after hot encoding: 44\n",
      "features listr: ['safe_loans' 'sub_grade_num' 'short_emp' 'emp_length_num' 'dti'\n",
      " 'payment_inc_ratio' 'delinq_2yrs' 'delinq_2yrs_zero' 'inq_last_6mths'\n",
      " 'last_delinq_none' 'last_major_derog_none' 'open_acc' 'pub_rec'\n",
      " 'pub_rec_zero' 'revol_util' 'total_rec_late_fee' 'int_rate'\n",
      " 'total_rec_int' 'annual_inc' 'funded_amnt' 'funded_amnt_inv' 'installment'\n",
      " 'grade_A' 'grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'home_ownership_MORTGAGE' 'home_ownership_OTHER' 'home_ownership_OWN'\n",
      " 'home_ownership_RENT' 'purpose_car' 'purpose_credit_card'\n",
      " 'purpose_debt_consolidation' 'purpose_home_improvement' 'purpose_house'\n",
      " 'purpose_major_purchase' 'purpose_medical' 'purpose_moving'\n",
      " 'purpose_other' 'purpose_small_business' 'purpose_vacation'\n",
      " 'purpose_wedding']\n"
     ]
    }
   ],
   "source": [
    "dataFile = r'lending-club-data.csv'\n",
    "#1. Load in the LendingClub dataset \n",
    "loans = pd.read_csv(dataFile, header=0, low_memory=False)\n",
    "#2. Reassign the labels to have +1 for a safe loan, and -1 for a risky (bad) loan.\n",
    "#The target column (label column) of the dataset that we are interested in is \n",
    "#called bad_loans. In this column 1means a risky (bad) loan 0 means a safe loan.\n",
    "#In order to make this more intuitive and consistent with the lectures, we reassign the target to be:\n",
    "#+1 as a safe loan\n",
    "#-1 as a risky (bad) loan\n",
    "#3. We put this in a new column called safe_loans.\n",
    "\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "#delete column 'bad_loans'\n",
    "loans = loans.drop('bad_loans', 1)\n",
    "\n",
    "#Exploring some features\n",
    "#2. Let's quickly explore what the dataset looks like. \n",
    "#First, print out the column names to see what features we have in this dataset.\n",
    "features = loans.columns.values\n",
    "print('Number of features in original data file:', np.shape(features)[0])\n",
    "\n",
    "#Selecting features\n",
    "#In this assignment, we will be using a subset of features (categorical and numeric). \n",
    "#The features we will be using are described in the code comments below. \n",
    "#If you are a finance geek, the LendingClub website has a lot more details about these features.\n",
    "target = 'safe_loans'\n",
    "features = ['grade',                     # grade of the loan (categorical)\n",
    "            'sub_grade_num',             # sub-grade of the loan as a number from 0 to 1\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'payment_inc_ratio',         # ratio of the monthly payment to income\n",
    "            'delinq_2yrs',               # number of delinquincies\n",
    "             'delinq_2yrs_zero',          # no delinquincies in last 2 years\n",
    "            'inq_last_6mths',            # number of creditor inquiries in last 6 months\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'open_acc',                  # number of open credit accounts\n",
    "            'pub_rec',                   # number of derogatory public records\n",
    "            'pub_rec_zero',              # no derogatory public records\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "            'int_rate',                  # interest rate of the loan\n",
    "            'total_rec_int',             # interest received to date\n",
    "            'annual_inc',                # annual income of borrower\n",
    "            'funded_amnt',               # amount committed to the loan\n",
    "            'funded_amnt_inv',           # amount committed by investors for the loan\n",
    "            'installment',               # monthly payment owed by the borrower\n",
    "           ]\n",
    "\n",
    "#Recall from the lectures that one \n",
    "#common approach to coping with missing values is to \n",
    "#skip observations that contain missing values.\n",
    "\n",
    "loans = loans[[target] + features].dropna()\n",
    "print('Number of features in selected columns:', loans.shape[1] -1 )\n",
    "#Apply one-hot encoding to loans. Your tool may have a function for one-hot encoding. \n",
    "#Alternatively, see #7 for implementation hints.\n",
    "\n",
    "\n",
    "\n",
    "#One-hot encodingÂ¶\n",
    "#For scikit-learn's decision tree implementation, it numerical values for \n",
    "#it's data matrix. This means you will have to turn categorical variables into binary \n",
    "#features via one-hot encoding.\n",
    "#7. We've seen this same piece of code in earlier assignments. Again, feel free to use this \n",
    "#piece of code as is. Refer to the API documentation for a deeper understanding.\n",
    "loans = pd.get_dummies(loans)\n",
    "print('Number of features after hot encoding:', loans.shape[1] -1 )\n",
    "print('features listr:', loans.columns.values )\n",
    "\n",
    "#Note that the column names are slightly different now, since we used one-hot encoding.\n",
    "\n",
    "#Split data into training and validation\n",
    "#8. We split the data into training data and validation data.\n",
    "train_idx = json.load(open(r'module-8-assignment-1-train-idx.json')) \n",
    "validation_idx = json.load(open(r'module-8-assignment-1-validation-idx.json'))\n",
    "train_data = loans.iloc[train_idx]\n",
    "validation_data = loans.iloc[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Quiz question: What percentage of the predictions on sample_validation_data did model_5 get correct?\n",
      "accuracy: 0.7500\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Quiz question: For each row in the sample_validation_data, what is the probability (according model_5) of a loan being classified as safe??\n",
      "[[ 0.41642331  0.58357669]\n",
      " [ 0.46949689  0.53050311]\n",
      " [ 0.53807792  0.46192208]\n",
      " [ 0.39591639  0.60408361]]\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Quiz Question: Which loan has the highest probability of being classified as a safe loan?\n",
      "Answer: last loan\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Can you verify that for all the predictions with probability >= 0.5, the model predicted the label +1?\n",
      "[ 1  1 -1  1]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosted tree classifier\n",
    "#Gradient boosted trees are a powerful variant of boosting methods; they have been used to win many \n",
    "#Kaggle competitions, and have been widely used in industry. We will explore the predictive power of \n",
    "#multiple decision trees as opposed to a single decision tree.\n",
    "#Additional reading: If you are interested in gradient boosted trees, here is some additional reading material:\n",
    "\n",
    "#We will now train models to predict safe_loans using the features above. In this section, we will \n",
    "#experiment with training an ensemble of 5 trees.\n",
    "\n",
    "# Now, let's use the built-in scikit learn gradient boosting classifier \n",
    "#(sklearn.ensemble.GradientBoostingClassifier) to create a gradient boosted classifier on \n",
    "#the training data. You will need to import sklearn, sklearn.ensemble, and numpy.\n",
    "\n",
    "#convert df to numpy\n",
    "train_data_y = (train_data[target]).as_matrix()\n",
    "train_data_X = (train_data.drop(target, axis=1)).as_matrix()\n",
    "\n",
    "model_5 = GradientBoostingClassifier(n_estimators = 5, max_depth = 6)\n",
    "model_5.fit(train_data_X, train_data_y)\n",
    "\n",
    "#Making predictions\n",
    "#Just like we did in previous sections, let us consider a few positive and negative \n",
    "#examples from the validation set. We will do the following:\n",
    "#Predict whether or not a loan is likely to default.\n",
    "#Predict the probability with which the loan is likely to default.\n",
    "\n",
    "#10. First, let's grab 2 positive examples and 2 negative examples.\n",
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "sample_validation_data_risky = validation_risky_loans.iloc[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans.iloc[0:2]\n",
    "\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "#For each row in the sample_validation_data, write code to make model_5 predict whether or \n",
    "#not the loan is classified as a safe loan. (Hint: if you are using scikit-learn, you can \n",
    "#use the .predict() method)\n",
    "sple_val_data_y = (sample_validation_data[target]).as_matrix()\n",
    "sple_val_data_X = (sample_validation_data.drop(target, axis=1)).as_matrix()\n",
    "#get predictions:\n",
    "pred_model_5 = model_5.predict(sple_val_data_X)\n",
    "#Quiz question: What percentage of the predictions on sample_validation_data did model_5 get correct?\n",
    "# score on sample data(accuracy)\n",
    "acc_model5 = model_5.score(sple_val_data_X, sple_val_data_y)\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: What percentage of the predictions on sample_validation_data did model_5 get correct?')\n",
    "print('accuracy: %.4f' % acc_model5)\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "#Prediction Probabilities\n",
    "#12. For each row in the sample_validation_data, what is the probability (according model_5) \n",
    "#of a loan being classified as safe? (Hint: if you are using scikit-learn, you can use the .predict_proba() method)\n",
    "\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: For each row in the sample_validation_data, what is the probability (according model_5) of a loan being classified as safe??')\n",
    "print( model_5.predict_proba(sple_val_data_X))\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz Question: Which loan has the highest probability of being classified as a safe loan?')\n",
    "print( 'Answer: last loan')\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "#Checkpoint: Can you verify that for all the predictions with probability >= 0.5, the model predicted the label +1?\n",
    "print('****************************************************************************************************')\n",
    "print('Can you verify that for all the predictions with probability >= 0.5, the model predicted the label +1?')\n",
    "print( model_5.predict(sple_val_data_X))\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the validation data\n",
    "Recall that the accuracy is defined as follows:\n",
    "\\begin{align}\n",
    "accuracy = \\frac{correctly classified examples}{total examples}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "The accuracy of the model_5 on the validation_data?\n",
      "acc_model_5_for_validation: 0.6612\n",
      "****************************************************************************************************\n",
      "(9284,)\n",
      "****************************************************************************************************\n",
      "Quiz question: What is the number of false positives on the validation_data?\n",
      "1654\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Quiz question: What is the number of false negatives on the validation_data?\n",
      "1491\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the accuracy of the model_5 on the validation_data. \n",
    "#(Hint: if you are using scikit-learn, you can use the .score() method)\n",
    "val_data_y = (validation_data[target]).as_matrix()\n",
    "val_data_X = (validation_data.drop(target, axis=1)).as_matrix()\n",
    "acc_model_5_for_validation = model_5.score(val_data_X, val_data_y)\n",
    "print('****************************************************************************************************')\n",
    "print('The accuracy of the model_5 on the validation_data?')\n",
    "print('acc_model_5_for_validation: %.4f' % acc_model_5_for_validation)\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "#14. Calculate the number of false positives made by the model on the validation_data.\n",
    "pred_validation_data = model_5.predict(val_data_X)\n",
    "print(np.shape(pred_validation_data))\n",
    "#Quiz question: What is the number of false positives on the validation_data?\n",
    "val_data_y_and_pred = np.transpose(np.vstack((val_data_y, pred_validation_data)))\n",
    "\n",
    "false_positive = val_data_y_and_pred[(val_data_y_and_pred[:,1]==1)&(val_data_y_and_pred[:,0]==-1)]\n",
    "sum_false_positive = np.sum(false_positive[:,1])\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: What is the number of false positives on the validation_data?')\n",
    "print(sum_false_positive)\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "#15. Calculate the number of false negatives made by the model on the validation_data.\n",
    "false_negative = val_data_y_and_pred[(val_data_y_and_pred[:,1]==-1)&(val_data_y_and_pred[:,0]==1)]\n",
    "sum_false_negative = np.sum(false_negative[:,0])\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: What is the number of false negatives on the validation_data?')\n",
    "print(sum_false_negative)\n",
    "print('****************************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Quiz Question: Using the same costs of the false positives and false negatives, what is the cost of the mistakes made by the boosted tree model (model_5) as evaluated on the validation_set?\n",
      "47990000\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Comparison with decision trees\n",
    "#In this assignment, we saw that model_5 has an accuracy of approximately 0.67.\n",
    "#we calculate the cost of the mistakes made by the model. We again consider the same costs as follows:\n",
    "#False negatives: Assume a cost of $10,000 per false negative.\n",
    "#False positives: Assume a cost of $20,000 per false positive.\n",
    "#Using the costs defined above and the number of false positives and false negatives for the decision tree, \n",
    "#we can calculate the total cost of the mistakes made by the decision tree model as follows:\n",
    "cost = 10000 * sum_false_negative  + 20000 * sum_false_positive\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz Question: Using the same costs of the false positives and false negatives, what is the cost of the mistakes made by the boosted tree model (model_5) as evaluated on the validation_set?')\n",
    "print(cost)\n",
    "print('****************************************************************************************************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Quiz question: What grades are the top 5 loans?\n",
      "      grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G\n",
      "278       0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
      "4865      0.0      0.0      0.0      0.0      1.0      0.0      0.0\n",
      "6905      1.0      0.0      0.0      0.0      0.0      0.0      0.0\n",
      "8771      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
      "4789      1.0      0.0      0.0      0.0      0.0      0.0      0.0\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Quiz question: What grades are the bottom 5 loans (in the validation_data) with the lowest probability of being predicted as a safe loan?\n",
      "      grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G\n",
      "2980      0.0      0.0      0.0      0.0      1.0      0.0      0.0\n",
      "1932      0.0      0.0      0.0      0.0      1.0      0.0      0.0\n",
      "26        0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
      "1540      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
      "1854      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Most positive & negative loans.\n",
    "#In this section, we will find the loans that are most likely to be predicted safe. \n",
    "#We can do this in a few steps:\n",
    "\n",
    "#Step 1: Use the model_5 (the model with 5 trees) and make probability predictions \n",
    "#for all the loans in validation_data.\n",
    "#Step 2: Similar to what we did in the very first assignment, add the probability predictions as \n",
    "#a column called predictions into validation_data.\n",
    "#Step 3: Sort the data (in descreasing order) by the probability predictions.\n",
    "#17. Start here with Step 1 & Step 2. \n",
    "#Make predictions using model_5 for all examples in the validation_data.\n",
    "positive_class_proba_model_5 = model_5.predict_proba(val_data_X)[:,1]\n",
    "pd.options.mode.chained_assignment = None\n",
    "validation_data['prob_safe_loan'] = pd.Series(positive_class_proba_model_5)\n",
    "\n",
    "#18. Now, we are ready to go to Step 3. You can now use the prediction column to sort the loans \n",
    "#in validation_data (in descending order) by prediction probability. Find the top 5 loans \n",
    "#with the highest probability of being predicted as a safe loan.\n",
    "validation_data.sort_values('prob_safe_loan', ascending=False, inplace=True)\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: What grades are the top 5 loans?')\n",
    "grade_features = ['grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F', 'grade_G']\n",
    "print((validation_data[grade_features]).iloc[0:5])\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "validation_data.sort_values('prob_safe_loan', ascending=True, inplace=True)\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: What grades are the bottom 5 loans (in the validation_data) with the lowest probability of being predicted as a safe loan?')\n",
    "grade_features = ['grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F', 'grade_G']\n",
    "print((validation_data[grade_features]).iloc[0:5])\n",
    "print('****************************************************************************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Quiz Question: Which model has the best accuracy on the validation_data?\n",
      "Model 5: 0.661245152951\n",
      "Model 10: 0.666307626023\n",
      "Model 50: 0.6836492891\n",
      "Model 100: 0.688927186558\n",
      "Model 200: 0.689788884102\n",
      "Model 500: 0.686342093925\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Quiz Question: Is it always true that the model with the most trees will perform best on test data?\n",
      "No\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Effects of adding more trees\n",
    "#we will train 5 different ensemble classifiers in the form of gradient boosted trees.\n",
    "\n",
    "#Train models with 10, 50, 100, 200, and 500 trees. \n",
    "#Use the n_estimators parameter to control the number of trees. Remember to keep max_depth = 6.\n",
    "#Call these models model_10, model_50, model_100, model_200, and model_500, respectively. \n",
    "#This may take a few minutes to run.\n",
    "model_10 = GradientBoostingClassifier(n_estimators = 10, max_depth = 6)\n",
    "model_10.fit(train_data_X, train_data_y)\n",
    "model_50 = GradientBoostingClassifier(n_estimators = 50, max_depth = 6)\n",
    "model_50.fit(train_data_X, train_data_y)\n",
    "model_100 = GradientBoostingClassifier(n_estimators = 100, max_depth = 6)\n",
    "model_100.fit(train_data_X, train_data_y)\n",
    "model_200 = GradientBoostingClassifier(n_estimators = 200, max_depth = 6)\n",
    "model_200.fit(train_data_X, train_data_y)\n",
    "model_500 = GradientBoostingClassifier(n_estimators = 500, max_depth = 6)\n",
    "model_500.fit(train_data_X, train_data_y)\n",
    "\n",
    "val_data = validation_data.drop('prob_safe_loan', axis=1)\n",
    "val_data_y = (val_data[target]).as_matrix()\n",
    "val_data_X = (val_data.drop(target, axis=1)).as_matrix()\n",
    "\n",
    "#Compare accuracy on entire validation set\n",
    "#Now we will compare the predicitve accuracy of our models on the validation set.\n",
    "#21. Evaluate the accuracy of the 10, 50, 100, 200, and 500 tree models on the validation_data.\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz Question: Which model has the best accuracy on the validation_data?')\n",
    "print('Model 5:', model_5.score(val_data_X, val_data_y))\n",
    "print('Model 10:', model_10.score(val_data_X, val_data_y))\n",
    "print('Model 50:', model_50.score(val_data_X, val_data_y))\n",
    "print('Model 100:', model_100.score(val_data_X, val_data_y))\n",
    "print('Model 200:', model_200.score(val_data_X, val_data_y))\n",
    "print('Model 500:', model_500.score(val_data_X, val_data_y))\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "    \n",
    "print('****************************************************************************************************')\n",
    "print('Quiz Question: Is it always true that the model with the most trees will perform best on test data?')\n",
    "print('No')\n",
    "print('****************************************************************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training and validation error vs. number of trees\n",
    "Recall from the lecture that the classification error is defined as\n",
    "\n",
    "\\begin{align}\n",
    "classification error = 1 - accuracy\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.00000000e+00   3.34506569e-01]\n",
      " [  1.00000000e+01   3.28326930e-01]\n",
      " [  5.00000000e+01   2.83672318e-01]\n",
      " [  1.00000000e+02   2.53633897e-01]\n",
      " [  2.00000000e+02   2.15373868e-01]\n",
      " [  5.00000000e+02   2.15373868e-01]]\n",
      "[[  5.00000000e+00   3.38754847e-01]\n",
      " [  1.00000000e+01   3.33692374e-01]\n",
      " [  5.00000000e+01   3.16350711e-01]\n",
      " [  1.00000000e+02   3.11072813e-01]\n",
      " [  2.00000000e+02   3.10211116e-01]\n",
      " [  5.00000000e+02   3.10211116e-01]]\n",
      "****************************************************************************************************\n",
      "Quiz question: Does the training error reduce as the number of trees increases?\n",
      "Yes\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Quiz question: Is it always true that the validation error will reduce as the number of trees increases?\n",
      "No\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAFSCAYAAAAdAnxrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d643c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#In this section, we will plot the training and validation errors versus the number of trees \n",
    "#to get a sense of how these models are performing. \n",
    "#We will compare the 10, 50, 100, 200, and 500 tree models. \n",
    "#You will need matplotlib in order to visualize the plots.\n",
    "\n",
    "#22. First, make sure this block of code runs on your computer.\n",
    "def make_figure(dim, title, xlabel, ylabel, legend):\n",
    "    plt.rcParams['figure.figsize'] = dim\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend is not None:\n",
    "        plt.legend(loc=legend, prop={'size':15})\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()\n",
    "\n",
    "#In order to plot the classification errors (on the train_data and validation_data) versus the \n",
    "#number of trees, we will need lists of all the errors.\n",
    "training_errors = np.array([[5, 1-model_5.score(train_data_X, train_data_y)], [10, 1-model_10.score(train_data_X, train_data_y)], \\\n",
    "                     [50, 1-model_50.score(train_data_X, train_data_y)], [100, 1-model_100.score(train_data_X, train_data_y)], \\\n",
    "                     [200, 1-model_200.score(train_data_X, train_data_y)], [500, 1-model_200.score(train_data_X, train_data_y) ]])\n",
    "\n",
    "\n",
    "validation_errors = np.array([[5, 1-model_5.score(val_data_X, val_data_y)], [10, 1-model_10.score(val_data_X, val_data_y)], \\\n",
    "                     [50, 1-model_50.score(val_data_X, val_data_y)], [100, 1-model_100.score(val_data_X, val_data_y)], \\\n",
    "                     [200, 1-model_200.score(val_data_X, val_data_y)], [500, 1-model_200.score(val_data_X, val_data_y) ]])\n",
    "\n",
    "print(training_errors)\n",
    "print(validation_errors)\n",
    "#28. Run the following code to visualize the plots.\n",
    "plt.plot(training_errors[:,0], training_errors[:,1], linewidth=4.0, label='Training error')\n",
    "plt.plot(validation_errors[:,0], validation_errors[:,1], linewidth=4.0, label='Validation error')\n",
    "\n",
    "make_figure(dim=(10,5), title='Error vs number of trees',\n",
    "            xlabel='Number of trees',\n",
    "            ylabel='Classification error',\n",
    "            legend='best')\n",
    "\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: Does the training error reduce as the number of trees increases?')\n",
    "print('Yes')\n",
    "print('****************************************************************************************************')\n",
    "\n",
    "print('****************************************************************************************************')\n",
    "print('Quiz question: Is it always true that the validation error will reduce as the number of trees increases?')\n",
    "print('No')\n",
    "print('****************************************************************************************************')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
