\relax 
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Week 5}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Pro and Cons}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {0.2}Cost function}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.1}Binary vs. Multiclass}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.2}Calculate Cost function}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {0.3}Minimization of the Cost Function}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3.1}Compute Gradient}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of a network [3-5-5-4]. $l$ : layer , $s$: node in that layer\relax }}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {0.4}Implement Back Propagation Algorithm}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {0.5}Back propagation Intuition}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.5.1}Forward Propagation}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.5.2}Back Propagation}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {0.6}Implementation note}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {0.7}Gradient checking}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {0.8}Random Initialization for NN}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {0.9}Summary of NN implementation}{9}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {.1}Derivation of the node error term $\delta $}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {.2}links}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {.3}Good to know}{14}}
