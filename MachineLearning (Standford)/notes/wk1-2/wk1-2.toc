\contentsline {part}{I\hspace {1em}Week 1 and 2}{1}
\contentsline {section}{\numberline {0.1}Introduction / Definition }{2}
\contentsline {subsection}{\numberline {0.1.1}What is Machine Learning?}{2}
\contentsline {subsection}{\numberline {0.1.2}Supervised Learning}{2}
\contentsline {subsection}{\numberline {0.1.3}Supervised vs. Unsupervised Learning}{3}
\contentsline {section}{\numberline {0.2}Generative vs. Discriminative models}{4}
\contentsline {subsection}{\numberline {0.2.1}Discriminative models}{4}
\contentsline {subsection}{\numberline {0.2.2}Generative model}{4}
\contentsline {section}{\numberline {0.3}Supervised Learning: Linear regression with 1 variable/feature (aka univariable linear regression)}{4}
\contentsline {subsection}{\numberline {0.3.1}Application to the house pricing example}{5}
\contentsline {section}{\numberline {0.4}Multiple features}{6}
\contentsline {subsection}{\numberline {0.4.1}Hypothesis function for $n$ features}{6}
\contentsline {subsection}{\numberline {0.4.2} The Cost function $J(\theta )$}{7}
\contentsline {subsection}{\numberline {0.4.3}Gradient descent algorithm}{7}
\contentsline {section}{\numberline {0.5}Gradient descent in practice}{8}
\contentsline {subsection}{\numberline {0.5.1}Feature scaling: how to converge faster}{8}
\contentsline {subsection}{\numberline {0.5.2}Learning rate $\alpha $: how to converge faster}{9}
\contentsline {subsection}{\numberline {0.5.3}Polynomial regression}{9}
\contentsline {section}{\numberline {0.6}Normal Equations}{9}
\contentsline {chapter}{Appendices}{12}
\contentsline {chapter}{\numberline {A}Linear Algebra Review}{13}
\contentsline {section}{\numberline {A.1}1-indexed versus 0-indexed vector matrix}{13}
\contentsline {section}{\numberline {A.2}Matrix}{13}
\contentsline {subsection}{\numberline {A.2.1}Matrix size}{13}
\contentsline {subsection}{\numberline {A.2.2}Matrix Operation}{13}
\contentsline {subsubsection}{Matrix addition}{13}
\contentsline {subsubsection}{Matrix scalar multiplication}{13}
\contentsline {subsubsection}{Multiplication of 2 matrix}{14}
\contentsline {subsubsection}{Matrix Identity}{14}
\contentsline {subsubsection}{Matrix Inverse}{14}
\contentsline {subsubsection}{Transpose matrix $A^{\mathrm {T}}$}{14}
\contentsline {subsection}{\numberline {A.2.3}Derivative $\nabla _A f(A)$}{14}
\contentsline {subsection}{\numberline {A.2.4}Trace}{15}
\contentsline {chapter}{\numberline {B}Matlab}{16}
\contentsline {chapter}{\numberline {C}Exercise: Gradient Descent Matlab}{18}
