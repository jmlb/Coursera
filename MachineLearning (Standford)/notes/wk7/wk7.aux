\relax 
\providecommand\tcolorbox@label[2]{}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Week 7}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Optimization objectives}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}cost function}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}SVM Optimization Objective}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {0.2}SVM - Large Margin Classifier}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.1}constraint for SVM}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.2}For large C}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.3}Visualization of the decision boundary for large C}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces linearly separable data\relax }}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces if C is large, SVM will take into accoutn the presence of the outlier. Bit if C is not too large, there is less overfitting. \relax }}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {0.3}Mathematics behind Large Margin classifier}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax }}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax }}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax }}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {0.4}SVM Kernels I}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.4.1}Example}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax }}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.4.2}landmarks}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax }}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax }}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.4.3}How to choose the landmarks}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.4.4}How to choose C and $\sigma $}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {0.5}How to use an SVM}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {0.6}Multi-class Classification}{9}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {.1}question}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax }}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {.2}Vector inner product ($u^T v$)}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces $p$ is the length of projection of $v$ on $u$ (where $p$ is $\pm $-ive)\relax }}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {.3}SVM Intro}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Support vectors are simply the coordinates of individual observation ($x$, $y$).\relax }}{12}}
